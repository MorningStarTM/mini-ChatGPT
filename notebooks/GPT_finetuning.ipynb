{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets datasets trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-yVLy5cwVOK",
        "outputId": "733c644b-f7da-4ea5-f9aa-c4735d532da8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.5)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.44.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.33.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.8.0)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ealw1jpuoKvK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "num_workers = os.cpu_count()\n",
        "max_steps = 6000\n",
        "bf16 = False\n",
        "fp16 = True\n",
        "gradient_accumulation_steps = 2\n",
        "context_length = 512\n",
        "logging_steps = 500\n",
        "save_steps = 500\n",
        "learning_rate = 0.0001\n",
        "model_name = 'openai-community/gpt2'\n",
        "out_dir = 'outputs/gpt2-finetuned'"
      ],
      "metadata": {
        "id": "pEiXrhhT4W-t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if bf16:\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name).to(dtype=torch.bfloat16)\n",
        "else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "print(model)\n",
        "# Total parameters and trainable parameters.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")"
      ],
      "metadata": {
        "id": "cTGehdtNo1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814e6569-da8d-4d03-994d-b0fb1b58c828"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2SdpaAttention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "124,439,808 total parameters.\n",
            "124,439,808 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=False\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "Y42PFg485N5N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('JM-Lee/Phi-3-mini-128k-instruct_instruction')\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "MgcyrIDzyHly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7db2c6-1b14-4dc5-eb4b-7e325c340d67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['system', 'instruction', 'response'],\n",
            "        num_rows: 61135\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = dataset['train'].train_test_split(test_size=0.05, shuffle=True)\n",
        "dataset_train = full_dataset['train']\n",
        "dataset_valid = full_dataset['test']\n",
        "\n",
        "print(dataset_train)\n",
        "print(dataset_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FhhnhbW6Dp9",
        "outputId": "dab3ecee-adc4-4c2a-c1f1-bdce349089fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['system', 'instruction', 'response'],\n",
            "    num_rows: 58078\n",
            "})\n",
            "Dataset({\n",
            "    features: ['system', 'instruction', 'response'],\n",
            "    num_rows: 3057\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(example):\n",
        "    \"\"\"\n",
        "    Formatting function returning a list of samples (kind of necessary for SFT API).\n",
        "    \"\"\"\n",
        "    text = f\"### Instruction:\\n{example['system']}\\n\\n### Input:\\n{example['instruction']}\\n\\n### Response:\\n{example['response']}\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "B_NyYxx84rh8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{out_dir}/logs\",\n",
        "    evaluation_strategy='steps',\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    logging_strategy='steps',\n",
        "    save_strategy='steps',\n",
        "    logging_steps=logging_steps,\n",
        "    save_steps=save_steps,\n",
        "    save_total_limit=2,\n",
        "    bf16=bf16,\n",
        "    fp16=fp16,\n",
        "    report_to='tensorboard',\n",
        "    max_steps=max_steps,\n",
        "    dataloader_num_workers=num_workers,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type='constant',\n",
        ")"
      ],
      "metadata": {
        "id": "xQBfJxYs4xrG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_valid,\n",
        "    max_seq_length=context_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    formatting_func=preprocess_function,\n",
        "    packing=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_wEL7xq5Wi5",
        "outputId": "dc4a10fc-7c43-45f0-f784-fad09588c86e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = trainer.get_train_dataloader()\n",
        "for i, sample in enumerate(dataloader):\n",
        "    print(tokenizer.decode(sample['input_ids'][0]))\n",
        "    print('#'*50)\n",
        "    if i == 5:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fzV7nnM5ld6",
        "outputId": "4e960ee5-5ea5-494c-feac-cbf6572db7ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<Constitutions>\n",
            "1. You are a helpful and informative AI assistant.\n",
            "2. You should not respond with false information.\n",
            "3. When you solve the problem, you should think step by step.\n",
            "\n",
            "Make sure you follow the rules.\n",
            "\n",
            "### Input:\n",
            "Detailed Instructions: You are given an original reference as well as a system reference. Your task is to judge the quality of the system reference. If the utterance is grammatically correct and fluent output 1, else output 0.\n",
            "Problem:System Reference: what part of the city are you looking for?\n",
            "Original Reference: in what area are you looking for a hotel?.\n",
            "Solution:\n",
            "\n",
            "### Response:\n",
            "<|start_markup_id|>[[[1]]]<|end_markup_id|>\n",
            "<|start_physics_explanation_id|>The system reference provided is grammatically correct and fluent. It effectively conveys the same meaning as the original reference, asking about the specific area or location within the city where the user is seeking a hotel. Therefore, the system reference meets the criteria for a high-quality output. <|end_physics_explanation_id|><|endoftext|>### Instruction:\n",
            "\n",
            "You are helpful and informative ai assistant.\n",
            "\n",
            "<Constitutions>\n",
            "1. You are a helpful and informative AI assistant.\n",
            "2. You should not respond with false information.\n",
            "3. When you solve the problem, you should think step by step.\n",
            "\n",
            "Make sure you follow the rules.\n",
            "\n",
            "### Input:\n",
            "Detailed Instructions: In this task, you're given reviews of various products in multiple languages. Domain is English - en, Japanese - ja, German - de, French - fr, Chinese - zh, Spanish - es. Given a review you need to predict the language in which it was written from en, ja, de, fr, zh, es.\n",
            "Problem:Habe diesen Artikel bestellt,war auf meiner Wunschliste um 84% reduziert, bekommen habe ich eine Madenschraube. Durch Rücksprache mit dem Verkäufer wurde mir mitgeteilt, das der Fehler bei Amazon liegt. Ich habe zwar mein Geld zurück bekommen, aber von seiten Amazon wurde\n",
            "##################################################\n",
            " evidence to support the arguments.\n",
            "\n",
            "One of the primary advantages of peacekeeping missions is their potential to prevent violence and promote stability. Peacekeepers often serve as a buffer between conflicting parties, reducing the likelihood of violence and creating a conducive environment for peace talks. For instance, the United Nations Mission in Liberia (UNMIL) played a crucial role in ending the Second Liberian Civil War in 2003. The mission helped disarm combatants, support the implementation of the peace agreement, and facilitate the country's transition to democracy. Similarly, the United Nations Organization Stabilization Mission in the Democratic Republic of the Congo (MONUSCO) has been instrumental in protecting civilians and supporting the government in its efforts to stabilize the region.\n",
            "\n",
            "Moreover, peacekeeping missions can help rebuild war-torn societies by promoting human rights, supporting the rule of law, and fostering economic development. The United Nations Transitional Administration in East Timor (UNTAET), for example, played a significant role in establishing democratic institutions, promoting human rights, and facilitating the country's transition to independence. Similarly, the United Nations Mission in Sierra Leone (UNAMSIL) helped rebuild the country's infrastructure, support the disarmament, demobilization, and reintegration of ex-combatants, and promote the rule of law.\n",
            "\n",
            "However, peacekeeping missions also have their disadvantages. One of the main criticisms is their cost. Peacekeeping missions can be expensive, with the United Nations spending billions of dollars each year on these operations. Critics argue that these funds could be better spent on domestic issues, such as education, healthcare, and infrastructure. Furthermore, peacekeeping missions can sometimes be ineffective or even harmful to the communities they are meant to serve. For instance, the United Nations Assistance Mission for Rwanda (UNAMIR) was widely criticized for its failure to prevent the 1994 genocide in Rwanda, despite its mandate to protect civilians. Similarly, the United Nations Mission in South Sudan (UNMISS) has faced criticism for its inability to prevent violence and protect civilians in the country.\n",
            "\n",
            "Another potential disadvantage of peacekeeping missions is the risk of becoming a tool for political manipulation. Some argue that powerful countries may use peacekeeping missions to advance their interests, rather than genuinely promoting peace and stability. For instance, critics argue that the United States has used its influence to shape the mandates of peacekeeping missions in ways that align with its foreign policy objectives.\n",
            "\n",
            "In conclusion, peacekeeping missions have both advantages and disadvantages. While they have the potential to prevent violence, promote stability,\n",
            "##################################################\n",
            " 2015 में, एयरलाइन ने 24 लाख से अधिक यात्रियों को, 96% की लोड फैक्टर के साथ अपने गंतव्य स्थान पर पहुचाया\n",
            "\n",
            " Option A: यूरोप\n",
            "\n",
            " Option B: एन्ड्रोमीडा\n",
            "\n",
            " Option C: इबेरिया\n",
            "\n",
            " Option D: एशिया\n",
            "Output:\n",
            "\n",
            "### Response:\n",
            "The correct option to replace the <MASK> in the statement is:\n",
            "\n",
            "Option A: यूरोप\n",
            "\n",
            "The complete statement would be: \"वुएलिंग अफ्रीका, यूरोप और यूरोप के 100 से अधिक स्थलों के लिए उड़ान भरता है एवं यह स्पेन की सबसे बड़ी एयरलाइन है।\"\n",
            "\n",
            "This translates to: \"Veliganding, India and Europe together cover 100 and more locations for air travel, and this is the largest European airline of Spain.\"\n",
            "\n",
            "However, there seems to be a slight inconsistency in the statement. The phrase \"यूरोप और यूरोप\" (India and Europe\n",
            "##################################################\n",
            " power of the command line.\n",
            "Jeroen Janssens is an assistant professor of data science at Tilburg University. As an independent consultant and trainer, he helps organizations making sense of their data. Previously, he was a data scientist at Elsevier in Amsterdam and startups YPlan and Visual Revenue in New York City. Jeroen holds an MSc in artificial intelligence from Maastricht University and a PhD in machine learning from Tilburg University. He's passionate about building open source tools for data science.\n",
            "\n",
            "### Response:\n",
            "<|start_page_id|>1<|end_page_id|>\n",
            "<|start_speech_id|>assistant<|end_speech_id|>\n",
            "\n",
            "1. Enhanced Efficiency: Leveraging the command line can significantly speed up your data science workflow. It allows you to execute multiple commands in a single line, reducing the time spent on repetitive tasks.\n",
            "\n",
            "2. Improved Productivity: Command line tools offer a wide range of functionalities that can automate and streamline your data processing tasks. This can lead to increased productivity and efficiency.\n",
            "\n",
            "3. Greater Control: The command line provides a higher level of control over your data processing tasks. You can customize and fine-tune your commands to suit your specific needs.\n",
            "\n",
            "4. Cost-Effective: Using command line tools can be more cost-effective than using expensive software packages. It eliminates the need for costly licenses and reduces the overhead of maintaining software.\n",
            "\n",
            "5. Cross-Platform Compatibility: Command line tools are platform-independent, meaning they can be used across different operating systems like Windows, OS X, or Linux. This makes them a versatile tool for data scientists working in diverse environments.\n",
            "\n",
            "6. Enhanced Debugging: Command line tools often provide detailed error messages and logs, making it easier to debug and troubleshoot issues.\n",
            "\n",
            "7. Learning and Skill Development: Learning to use command line tools can enhance your programming skills and broaden your understanding of data science. It can also make you more versatile and adaptable in your career.\n",
            "\n",
            "8. Scalability: Command line tools are highly scalable. They can handle large volumes of data and complex computations, making them ideal for big data projects.\n",
            "\n",
            "9. Extensibility: Command line tools can be extended and customized to meet specific requirements. This makes them highly flexible and adaptable to changing needs.\n",
            "\n",
            "10. Data Science Toolbox: The Data Science Toolbox, as introduced\n",
            "##################################################\n",
            " education are more likely to secure better-paying jobs and have a higher standard of living.\n",
            "\n",
            "Access to Healthcare:\n",
            "\n",
            "Urbanization has led to an increase in the demand for healthcare services, as people move to cities in search of better opportunities. However, the rapid growth of urban areas has resulted in overcrowded hospitals, inadequate infrastructure, and a lack of qualified healthcare professionals. This has led to a disparity in the quality of healthcare between urban and rural areas. In many developing countries, urban hospitals are better equipped and have more resources than rural hospitals, leading to a gap in healthcare services. This disparity in healthcare perpetuates social inequality, as those who have access to quality healthcare are more likely to live longer and have a higher standard of living.\n",
            "\n",
            "Access to Housing:\n",
            "\n",
            "Urbanization has led to a significant increase in the demand for housing, as people move to cities in search of better opportunities. However, the rapid growth of urban areas has resulted in a shortage of affordable housing, leading to the proliferation of slums and informal settlements. This has led to a disparity in the quality of housing between urban and rural areas. In many developing countries, urban housing is more expensive and of lower quality than rural housing, leading to a gap in housing opportunities. This disparity in housing perpetuates social inequality, as those who have access to affordable housing are more likely to live in safe and healthy environments.\n",
            "\n",
            "Access to Employment:\n",
            "\n",
            "Urbanization has led to an increase in the demand for employment, as people move to cities in search of better opportunities. However, the rapid growth of urban areas has resulted in a shortage of jobs, leading to high unemployment rates and underemployment. This has led to a disparity in employment opportunities between urban and rural areas. In many developing countries, urban areas have a higher concentration of jobs in the formal sector, while rural areas have a higher concentration of informal sector jobs. This disparity in employment perpetuates social inequality, as those who have access to formal sector jobs are more likely to earn higher wages and have a higher standard of living.\n",
            "\n",
            "Access to Basic Amenities:\n",
            "\n",
            "Urbanization has led to an increase in the demand for basic amenities, such as water, sanitation, and electricity. However, the rapid growth of urban areas has resulted in a shortage of these amenities, leading to inadequate infrastructure and a lack of access to basic services. This has led to a disparity in the quality of basic amenities between urban and rural areas. In many developing countries, urban areas have better access\n",
            "##################################################\n",
            " You should not respond with false information.\n",
            "3. When you solve the problem, you should think step by step.\n",
            "\n",
            "Make sure you follow the rules.\n",
            "\n",
            "### Input:\n",
            "As telemedicine becomes increasingly popular, it is important to examine its potential benefits and drawbacks when used in conjunction with traditional in-person medical care. Research indicates that telemedicine can increase access to care and improve patient outcomes, particularly for individuals living in remote or underserved areas. However, it is crucial to consider the unique needs and limitations of each patient when determining the appropriate use of telemedicine. Healthcare providers must take into account factors such as the patient's technological literacy, the complexity of their medical condition, and their preferences for in-person vs. virtual care. Can you add a missing paragraph that further elaborates on the patient-specific considerations that healthcare providers should keep in mind when utilizing telemedicine as part of standard medical care?\n",
            "\n",
            "### Response:\n",
            "Certainly! Here's a paragraph that further elaborates on the patient-specific considerations that healthcare providers should keep in mind when utilizing telemedicine as part of standard medical care:\n",
            "\n",
            "In addition to the factors mentioned earlier, healthcare providers should also consider the patient's cultural background, language proficiency, and health literacy when utilizing telemedicine. For example, patients who are not fluent in the language used during telemedicine consultations may struggle to understand medical instructions or express their symptoms accurately. Similarly, patients from different cultural backgrounds may have different beliefs and attitudes towards healthcare, which can affect their willingness to engage in telemedicine. Healthcare providers should also be aware of the potential for technology-related barriers, such as poor internet connectivity or lack of access to necessary devices, which can limit the effectiveness of telemedicine for some patients. By taking these patient-specific considerations into account, healthcare providers can ensure that telemedicine is used in a way that is both effective and equitable for all patients.<|endoftext|>### Instruction:\n",
            "\n",
            "You are helpful and informative ai assistant.\n",
            "\n",
            "<Constitutions>\n",
            "1. You are a helpful and informative AI assistant.\n",
            "2. You should not respond with false information.\n",
            "3. When you solve the problem, you should think step by step.\n",
            "\n",
            "Make sure you follow the rules.\n",
            "\n",
            "### Input:\n",
            "Write a fictional short story of 1000-1500 words that explores the journey of a character discovering their passion through their travel experiences. Develop the protagonist's personality and\n",
            "##################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "tUCCSVN27v4T",
        "outputId": "b12374c6-ea63-428a-afc4-2e921dc7be93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6000/6000 1:07:03, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.580800</td>\n",
              "      <td>1.681918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.555100</td>\n",
              "      <td>1.672241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.548700</td>\n",
              "      <td>1.669227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.556700</td>\n",
              "      <td>1.667471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.561300</td>\n",
              "      <td>1.665127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.538500</td>\n",
              "      <td>1.638500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.699500</td>\n",
              "      <td>1.623000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.703500</td>\n",
              "      <td>1.616680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.711400</td>\n",
              "      <td>1.610285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.695600</td>\n",
              "      <td>1.602721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.674700</td>\n",
              "      <td>1.597414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.666200</td>\n",
              "      <td>1.592869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(f\"{out_dir}/best_model\")\n",
        "tokenizer.save_pretrained(f\"{out_dir}/best_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzoS81gh8ANf",
        "outputId": "d97df462-5621-4d65-f8a1-d3730bb7f1d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('outputs/gpt2-finetuned/best_model/tokenizer_config.json',\n",
              " 'outputs/gpt2-finetuned/best_model/special_tokens_map.json',\n",
              " 'outputs/gpt2-finetuned/best_model/vocab.json',\n",
              " 'outputs/gpt2-finetuned/best_model/merges.txt',\n",
              " 'outputs/gpt2-finetuned/best_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "lZPaQJrKi3sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "pipe = pipeline(\n",
        "    task='text-generation',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=512, # Prompt + new tokens to generate.\n",
        "    device_map=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaHWMyzXi-7E",
        "outputId": "6d2e1c99-c55a-4efc-a70d-ebdc908ca60d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"### Instruction:\n",
        "{}\n",
        "### Input:\n",
        "{}\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "instructions = 'Write three tips to study well for exam.'\n",
        "inputs = ''\n",
        "response = ''\n",
        "prompt = template.format(instructions, inputs, response)"
      ],
      "metadata": {
        "id": "ePmQd-pujNj1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = pipe(\n",
        "    prompt,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.1,\n",
        ")\n",
        "print(outputs[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqOsnQBajXXP",
        "outputId": "b66cbef3-29cb-4135-b028-c13396d70a4e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Write three tips to study well for exam.\n",
            "### Input:\n",
            "\n",
            "### Response:\n",
            "1. **Understanding Your Learning Style**: Begin by understanding the structure of your exams and the key topics. This will help you understand how they are designed, the learning style, and the overall learning experience.\n",
            "\n",
            "2. **Set Boundaries and Expectations**: Make sure that your answers align with your learning style. This includes understanding your subject matter, understanding the topics, and the objectives of each topic.\n",
            "   - **Understand Your Topic**: Learn about different types of questions and explain why they are relevant to your learning style.\n",
            "   - **Follow the Process**: Follow the process of setting up the questions and providing them with clear instructions.\n",
            "   - **Review and Adjust**: Once everything is set in place, review your answers and adjust your schedule as needed.\n",
            "\n",
            "3. **Practice and Experiment**: Continuously practice and experiment with different subjects to see how you learn. This will help you develop your knowledge and apply it effectively in different situations.\n",
            "\n",
            "4. **Stay Updated**: Keep up-to-date with the latest research and techniques in your field. This will help you stay updated on the latest research and techniques.\n",
            "\n",
            "5. **Learn Different Types of Questions**: Learn different types of questions to better understand their context and potential application in different scenarios. This will help you develop a deeper understanding of your material.\n",
            "\n",
            "6. **Stay Updated**: Keep up-to-date with the latest research and techniques in your field. This will help you stay updated on the latest research and techniques.\n",
            "\n",
            "7. **Stay Organized and Adaptable**: Keep a plan for your assignments and deadlines. This may involve organizing and managing your tasks, making time for new projects, or scheduling activities.\n",
            "\n",
            "8. **Stay Motivated and Engaged**: Keep a positive attitude and engage in activities that make you feel motivated and engaged. This will help you stay motivated and engaged in the learning process.\n",
            "\n",
            "9. **Take Breaks and Rest**: Take breaks and rest throughout the day to recharge and improve your focus. This will help you recharge and improve your overall performance.\n",
            "\n",
            "10. **Stay Comfortable and Encouraged**: Be open to feedback and encourage others to try new things and improve their learning. This will help you stay committed to your learning and improve your performance.\n",
            "\n",
            "Remember,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7N9Z09q5kDIz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}